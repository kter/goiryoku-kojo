{
  "version": 4,
  "terraform_version": "1.14.3",
  "serial": 9,
  "lineage": "c7535d9c-5889-c168-cb1a-41a4ea1fc0ab",
  "outputs": {},
  "resources": [
    {
      "mode": "data",
      "type": "archive_file",
      "name": "generate_words_source",
      "provider": "provider[\"registry.terraform.io/hashicorp/archive\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "exclude_symlink_directories": null,
            "excludes": null,
            "id": "dce29726b59038da59960a6f579716d3d67209ff",
            "output_base64sha256": "1BZe1WbcY7P+8Mtv6NFecmiEqWwhYgNzLMY50XoNf0c=",
            "output_base64sha512": "WX1m9ALMVsbxTHJIMl8Muz+pz/qoyZuMX78YoD5SCFIXqwGB8DZ8/unQWvG6fTkZHUp1ugQmmD9tllaB7MwDtQ==",
            "output_file_mode": null,
            "output_md5": "4b55770599df63e585f756c4636cb59d",
            "output_path": "./tmp/generate_words.zip",
            "output_sha": "dce29726b59038da59960a6f579716d3d67209ff",
            "output_sha256": "d4165ed566dc63b3fef0cb6fe8d15e726884a96c216203732cc639d17a0d7f47",
            "output_sha512": "597d66f402cc56c6f14c7248325f0cbb3fa9cffaa8c99b8c5fbf18a03e52085217ab0181f0367cfee9d05af1ba7d39191d4a75ba0426983f6d965681eccc03b5",
            "output_size": 5341,
            "source": [
              {
                "content": "# Shared utilities for Cloud Functions\n",
                "filename": "__init__.py"
              },
              {
                "content": "\"\"\"Batch function to generate vocabulary words using Gemini 1.5 Flash.\"\"\"\n\nimport logging\nfrom datetime import date, timedelta\nfrom http import HTTPStatus\n\nimport functions_framework\nfrom flask import Request, Response\n\n# Add shared module to path\nimport sys\nimport os\nsys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'shared'))\n\nfrom firestore_client import FirestoreClient\nfrom gemini_client import GeminiClient, GeminiClientError\n\nlogger = logging.getLogger(__name__)\n\n\ndef get_missing_dates(\n    firestore_client: FirestoreClient,\n    start_date: date,\n    end_date: date\n) -\u003e list[str]:\n    \"\"\"Find dates that don't have words generated yet.\n    \n    Args:\n        firestore_client: Firestore client instance.\n        start_date: Start date (inclusive).\n        end_date: End date (inclusive).\n        \n    Returns:\n        List of missing date strings (YYYY-MM-DD).\n    \"\"\"\n    existing_dates = firestore_client.get_existing_dates(start_date, end_date)\n    \n    missing_dates = []\n    current = start_date\n    while current \u003c= end_date:\n        date_str = current.isoformat()\n        if date_str not in existing_dates:\n            missing_dates.append(date_str)\n        current += timedelta(days=1)\n    \n    return missing_dates\n\n\n@functions_framework.http\ndef generate_words(request: Request) -\u003e Response:\n    \"\"\"HTTP Cloud Function to generate vocabulary words.\n    \n    Triggered by Cloud Scheduler daily at 0:00 JST.\n    Generates words for any missing dates in the next 7 days.\n    \n    Args:\n        request: Flask request object.\n        \n    Returns:\n        JSON response with generation results.\n    \"\"\"\n    try:\n        # Initialize clients\n        firestore_client = FirestoreClient()\n        gemini_client = GeminiClient()\n        \n        # Define date range: today to 7 days ahead\n        today = date.today()\n        end_date = today + timedelta(days=7)\n        \n        # Find missing dates\n        missing_dates = get_missing_dates(firestore_client, today, end_date)\n        \n        if not missing_dates:\n            logger.info(\"No missing dates found. Skipping generation.\")\n            return Response(\n                '{\"success\": true, \"message\": \"No generation needed\", \"generated\": 0}',\n                status=HTTPStatus.OK,\n                mimetype=\"application/json\"\n            )\n        \n        logger.info(f\"Generating words for {len(missing_dates)} dates: {missing_dates}\")\n        \n        # Get recent words to avoid duplication\n        recent_words = firestore_client.get_recent_words(days=10)\n        recent_word_list = [w[\"word\"] for w in recent_words]\n        \n        logger.info(f\"Recent words to avoid: {recent_word_list}\")\n        \n        # Generate words using Gemini\n        generated_words = gemini_client.generate_words(\n            dates=missing_dates,\n            recent_words=recent_word_list\n        )\n        \n        if not generated_words:\n            logger.warning(\"No words generated from Gemini\")\n            return Response(\n                '{\"success\": false, \"error\": \"No words generated\", \"generated\": 0}',\n                status=HTTPStatus.INTERNAL_SERVER_ERROR,\n                mimetype=\"application/json\"\n            )\n        \n        # Save to Firestore\n        saved_count = firestore_client.save_words(generated_words)\n        \n        logger.info(f\"Successfully generated and saved {saved_count} words\")\n        \n        return Response(\n            f'{{\"success\": true, \"generated\": {saved_count}, \"dates\": {missing_dates}}}',\n            status=HTTPStatus.OK,\n            mimetype=\"application/json\"\n        )\n        \n    except GeminiClientError as e:\n        logger.error(f\"Gemini API error: {e}\")\n        return Response(\n            f'{{\"success\": false, \"error\": \"AI generation failed: {str(e)}\"}}',\n            status=HTTPStatus.INTERNAL_SERVER_ERROR,\n            mimetype=\"application/json\"\n        )\n    except Exception as e:\n        logger.error(f\"Unexpected error: {e}\")\n        return Response(\n            f'{{\"success\": false, \"error\": \"Internal server error\"}}',\n            status=HTTPStatus.INTERNAL_SERVER_ERROR,\n            mimetype=\"application/json\"\n        )\n",
                "filename": "main.py"
              },
              {
                "content": "\"\"\"Firestore client for vocabulary words management.\"\"\"\n\nfrom datetime import date, timedelta\nfrom typing import Optional\nfrom google.cloud import firestore\n\n\nclass FirestoreClient:\n    \"\"\"Client for interacting with Firestore to manage vocabulary words.\"\"\"\n\n    COLLECTION_NAME = \"words\"\n\n    def __init__(self, project_id: Optional[str] = None):\n        \"\"\"Initialize Firestore client.\n        \n        Args:\n            project_id: Optional GCP project ID. If None, uses default.\n        \"\"\"\n        if project_id:\n            self._db = firestore.Client(project=project_id)\n        else:\n            self._db = firestore.Client()\n\n    def get_words_by_date_range(\n        self, start_date: date, end_date: date\n    ) -\u003e list[dict]:\n        \"\"\"Get words within a date range.\n        \n        Args:\n            start_date: Start date (inclusive).\n            end_date: End date (inclusive).\n            \n        Returns:\n            List of word documents found within the range.\n            Missing dates are simply not included (no error).\n        \"\"\"\n        start_str = start_date.isoformat()\n        end_str = end_date.isoformat()\n\n        docs = (\n            self._db.collection(self.COLLECTION_NAME)\n            .where(\"date\", \"\u003e=\", start_str)\n            .where(\"date\", \"\u003c=\", end_str)\n            .order_by(\"date\")\n            .stream()\n        )\n\n        return [doc.to_dict() for doc in docs]\n\n    def get_recent_words(self, days: int = 10) -\u003e list[dict]:\n        \"\"\"Get words from the last N days.\n        \n        Args:\n            days: Number of days to look back.\n            \n        Returns:\n            List of recent word documents.\n        \"\"\"\n        end_date = date.today()\n        start_date = end_date - timedelta(days=days)\n        return self.get_words_by_date_range(start_date, end_date)\n\n    def get_existing_dates(\n        self, start_date: date, end_date: date\n    ) -\u003e set[str]:\n        \"\"\"Get set of dates that already have words.\n        \n        Args:\n            start_date: Start date (inclusive).\n            end_date: End date (inclusive).\n            \n        Returns:\n            Set of date strings (YYYY-MM-DD) that exist.\n        \"\"\"\n        words = self.get_words_by_date_range(start_date, end_date)\n        return {word[\"date\"] for word in words}\n\n    def save_words(self, words: list[dict]) -\u003e int:\n        \"\"\"Save generated words to Firestore.\n        \n        Args:\n            words: List of word dictionaries with 'date', 'word', 'reading' keys.\n            \n        Returns:\n            Number of words saved.\n        \"\"\"\n        batch = self._db.batch()\n        count = 0\n\n        for word in words:\n            # Use date as document ID for easy lookup and deduplication\n            doc_ref = self._db.collection(self.COLLECTION_NAME).document(\n                word[\"date\"]\n            )\n            batch.set(doc_ref, word)\n            count += 1\n\n        batch.commit()\n        return count\n\n    def get_word_by_date(self, target_date: date) -\u003e Optional[dict]:\n        \"\"\"Get a single word by date.\n        \n        Args:\n            target_date: The date to look up.\n            \n        Returns:\n            Word document if found, None otherwise.\n        \"\"\"\n        doc_ref = self._db.collection(self.COLLECTION_NAME).document(\n            target_date.isoformat()\n        )\n        doc = doc_ref.get()\n\n        if doc.exists:\n            return doc.to_dict()\n        return None\n",
                "filename": "firestore_client.py"
              },
              {
                "content": "\"\"\"Gemini client for vocabulary word generation using Vertex AI.\"\"\"\n\nimport json\nimport logging\nfrom typing import Optional\n\nimport vertexai\nfrom vertexai.generative_models import GenerativeModel, GenerationConfig\n\nlogger = logging.getLogger(__name__)\n\n\nclass GeminiClientError(Exception):\n    \"\"\"Base exception for Gemini client errors.\"\"\"\n    pass\n\n\nclass GeminiParseError(GeminiClientError):\n    \"\"\"Raised when response cannot be parsed as expected JSON.\"\"\"\n    pass\n\n\nclass GeminiClient:\n    \"\"\"Client for generating vocabulary words using Gemini 1.5 Flash.\"\"\"\n\n    MODEL_NAME = \"gemini-1.5-flash\"\n    \n    SYSTEM_PROMPT = \"\"\"あなたは日本語の語彙力トレーニングアプリのための単語生成AIです。\n\nあなたの役割は、指定された日付に対して抽象的で少し難しい日本語の名詞を生成することです。\n\n## 出力ルール\n- 必ず以下のJSON形式のみで出力してください。説明文や追加のテキストは一切含めないでください。\n- 各単語は「word」(漢字表記)と「reading」(ひらがな読み)を含めてください。\n\n## JSON形式\n{\n  \"words\": [\n    {\n      \"date\": \"YYYY-MM-DD\",\n      \"word\": \"単語\",\n      \"reading\": \"たんご\"\n    }\n  ]\n}\n\n## 単語選定基準\n- 抽象的な概念を表す名詞を選ぶこと\n- 日常会話ではあまり使われないが、知っていると語彙力が高いと感じられる単語\n- 小学校高学年〜中学生レベルの漢字で構成される単語\n- 例: 概念、帰結、矛盾、逆説、恩恵、弊害、風潮、慣習、素養、気概\"\"\"\n\n    def __init__(\n        self,\n        project_id: Optional[str] = None,\n        location: str = \"asia-northeast1\"\n    ):\n        \"\"\"Initialize Gemini client.\n        \n        Args:\n            project_id: GCP project ID.\n            location: Vertex AI location.\n        \"\"\"\n        vertexai.init(project=project_id, location=location)\n        self._model = GenerativeModel(\n            self.MODEL_NAME,\n            system_instruction=self.SYSTEM_PROMPT\n        )\n        self._generation_config = GenerationConfig(\n            temperature=0.8,\n            max_output_tokens=2048,\n            response_mime_type=\"application/json\"\n        )\n\n    def generate_words(\n        self,\n        dates: list[str],\n        recent_words: list[str]\n    ) -\u003e list[dict]:\n        \"\"\"Generate vocabulary words for specified dates.\n        \n        Args:\n            dates: List of date strings (YYYY-MM-DD) to generate words for.\n            recent_words: List of recent words to avoid duplication.\n            \n        Returns:\n            List of generated word dictionaries.\n            \n        Raises:\n            GeminiParseError: If response cannot be parsed.\n            GeminiClientError: For other API errors.\n        \"\"\"\n        if not dates:\n            return []\n\n        # Build prompt with context\n        recent_words_str = \"、\".join(recent_words) if recent_words else \"なし\"\n        dates_str = \", \".join(dates)\n        \n        prompt = f\"\"\"以下の日付に対して、それぞれ1つずつ抽象的で少し難しい日本語の名詞を生成してください。\n\n対象日付: {dates_str}\n\n## 重複回避\n以下の直近の単語とは重複しない単語を選んでください:\n{recent_words_str}\n\n上記の形式で、{len(dates)}件の単語をJSON形式で出力してください。\"\"\"\n\n        try:\n            response = self._model.generate_content(\n                prompt,\n                generation_config=self._generation_config\n            )\n            \n            return self._parse_response(response.text)\n            \n        except json.JSONDecodeError as e:\n            logger.error(f\"Failed to parse Gemini response: {e}\")\n            raise GeminiParseError(f\"Invalid JSON response: {e}\") from e\n        except Exception as e:\n            logger.error(f\"Gemini API error: {e}\")\n            raise GeminiClientError(f\"API error: {e}\") from e\n\n    def _parse_response(self, response_text: str) -\u003e list[dict]:\n        \"\"\"Parse and validate the JSON response.\n        \n        Args:\n            response_text: Raw response text from Gemini.\n            \n        Returns:\n            List of validated word dictionaries.\n            \n        Raises:\n            GeminiParseError: If parsing or validation fails.\n        \"\"\"\n        try:\n            # Clean response text (remove markdown code blocks if present)\n            cleaned = response_text.strip()\n            if cleaned.startswith(\"```json\"):\n                cleaned = cleaned[7:]\n            if cleaned.startswith(\"```\"):\n                cleaned = cleaned[3:]\n            if cleaned.endswith(\"```\"):\n                cleaned = cleaned[:-3]\n            cleaned = cleaned.strip()\n\n            data = json.loads(cleaned)\n            \n            if \"words\" not in data:\n                raise GeminiParseError(\"Response missing 'words' key\")\n            \n            words = data[\"words\"]\n            validated_words = []\n            \n            for word in words:\n                if not all(k in word for k in [\"date\", \"word\", \"reading\"]):\n                    logger.warning(f\"Skipping invalid word entry: {word}\")\n                    continue\n                validated_words.append({\n                    \"date\": word[\"date\"],\n                    \"word\": word[\"word\"],\n                    \"reading\": word[\"reading\"]\n                })\n            \n            return validated_words\n            \n        except json.JSONDecodeError as e:\n            raise GeminiParseError(f\"Failed to parse JSON: {e}\") from e\n",
                "filename": "gemini_client.py"
              },
              {
                "content": "functions-framework==3.*\ngoogle-cloud-firestore\u003e=2.14.0\ngoogle-cloud-aiplatform\u003e=1.38.0\nflask\u003e=2.0.0\n",
                "filename": "requirements.txt"
              }
            ],
            "source_content": null,
            "source_content_filename": null,
            "source_dir": null,
            "source_file": null,
            "type": "zip"
          },
          "sensitive_attributes": [],
          "identity_schema_version": 0
        }
      ]
    },
    {
      "mode": "data",
      "type": "archive_file",
      "name": "get_words_source",
      "provider": "provider[\"registry.terraform.io/hashicorp/archive\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "exclude_symlink_directories": null,
            "excludes": null,
            "id": "b5997c2cacf8dba26b0ef7f171087195d5f8b7e6",
            "output_base64sha256": "NJ/BkcvkNnvxjk+YU8a/qFqzSo6GsY1sJRWf74pR/bs=",
            "output_base64sha512": "OmVPOEKv6FofANbNKZosZeWTO+03dEmTbN4X7gFVpSJFgEGOAJHfDl4cVl7J8atGyDJQ2d33AAJqvryWaUmNVA==",
            "output_file_mode": null,
            "output_md5": "788550f33b15797d86a274d7b41f99b2",
            "output_path": "./tmp/get_words.zip",
            "output_sha": "b5997c2cacf8dba26b0ef7f171087195d5f8b7e6",
            "output_sha256": "349fc191cbe4367bf18e4f9853c6bfa85ab34a8e86b18d6c25159fef8a51fdbb",
            "output_sha512": "3a654f3842afe85a1f00d6cd299a2c65e5933bed377449936cde17ee0155a5224580418e0091df0e5e1c565ec9f1ab46c83250d9ddf700026abebc9669498d54",
            "output_size": 2903,
            "source": [
              {
                "content": "# Shared utilities for Cloud Functions\n",
                "filename": "__init__.py"
              },
              {
                "content": "\"\"\"Firestore client for vocabulary words management.\"\"\"\n\nfrom datetime import date, timedelta\nfrom typing import Optional\nfrom google.cloud import firestore\n\n\nclass FirestoreClient:\n    \"\"\"Client for interacting with Firestore to manage vocabulary words.\"\"\"\n\n    COLLECTION_NAME = \"words\"\n\n    def __init__(self, project_id: Optional[str] = None):\n        \"\"\"Initialize Firestore client.\n        \n        Args:\n            project_id: Optional GCP project ID. If None, uses default.\n        \"\"\"\n        if project_id:\n            self._db = firestore.Client(project=project_id)\n        else:\n            self._db = firestore.Client()\n\n    def get_words_by_date_range(\n        self, start_date: date, end_date: date\n    ) -\u003e list[dict]:\n        \"\"\"Get words within a date range.\n        \n        Args:\n            start_date: Start date (inclusive).\n            end_date: End date (inclusive).\n            \n        Returns:\n            List of word documents found within the range.\n            Missing dates are simply not included (no error).\n        \"\"\"\n        start_str = start_date.isoformat()\n        end_str = end_date.isoformat()\n\n        docs = (\n            self._db.collection(self.COLLECTION_NAME)\n            .where(\"date\", \"\u003e=\", start_str)\n            .where(\"date\", \"\u003c=\", end_str)\n            .order_by(\"date\")\n            .stream()\n        )\n\n        return [doc.to_dict() for doc in docs]\n\n    def get_recent_words(self, days: int = 10) -\u003e list[dict]:\n        \"\"\"Get words from the last N days.\n        \n        Args:\n            days: Number of days to look back.\n            \n        Returns:\n            List of recent word documents.\n        \"\"\"\n        end_date = date.today()\n        start_date = end_date - timedelta(days=days)\n        return self.get_words_by_date_range(start_date, end_date)\n\n    def get_existing_dates(\n        self, start_date: date, end_date: date\n    ) -\u003e set[str]:\n        \"\"\"Get set of dates that already have words.\n        \n        Args:\n            start_date: Start date (inclusive).\n            end_date: End date (inclusive).\n            \n        Returns:\n            Set of date strings (YYYY-MM-DD) that exist.\n        \"\"\"\n        words = self.get_words_by_date_range(start_date, end_date)\n        return {word[\"date\"] for word in words}\n\n    def save_words(self, words: list[dict]) -\u003e int:\n        \"\"\"Save generated words to Firestore.\n        \n        Args:\n            words: List of word dictionaries with 'date', 'word', 'reading' keys.\n            \n        Returns:\n            Number of words saved.\n        \"\"\"\n        batch = self._db.batch()\n        count = 0\n\n        for word in words:\n            # Use date as document ID for easy lookup and deduplication\n            doc_ref = self._db.collection(self.COLLECTION_NAME).document(\n                word[\"date\"]\n            )\n            batch.set(doc_ref, word)\n            count += 1\n\n        batch.commit()\n        return count\n\n    def get_word_by_date(self, target_date: date) -\u003e Optional[dict]:\n        \"\"\"Get a single word by date.\n        \n        Args:\n            target_date: The date to look up.\n            \n        Returns:\n            Word document if found, None otherwise.\n        \"\"\"\n        doc_ref = self._db.collection(self.COLLECTION_NAME).document(\n            target_date.isoformat()\n        )\n        doc = doc_ref.get()\n\n        if doc.exists:\n            return doc.to_dict()\n        return None\n",
                "filename": "firestore_client.py"
              },
              {
                "content": "\"\"\"HTTP function to get vocabulary words for the mobile app.\"\"\"\n\nimport json\nimport logging\nfrom datetime import date, timedelta\nfrom http import HTTPStatus\n\nimport functions_framework\nfrom flask import Request, Response\n\n# Add shared module to path\nimport sys\nimport os\nsys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'shared'))\n\nfrom firestore_client import FirestoreClient\n\nlogger = logging.getLogger(__name__)\n\n# CORS headers for Flutter app access\nCORS_HEADERS = {\n    \"Access-Control-Allow-Origin\": \"*\",\n    \"Access-Control-Allow-Methods\": \"GET, OPTIONS\",\n    \"Access-Control-Allow-Headers\": \"Content-Type\",\n    \"Access-Control-Max-Age\": \"3600\",\n}\n\n\ndef create_response(\n    data: dict,\n    status: int = HTTPStatus.OK\n) -\u003e Response:\n    \"\"\"Create a JSON response with CORS headers.\n    \n    Args:\n        data: Response data dictionary.\n        status: HTTP status code.\n        \n    Returns:\n        Flask Response object.\n    \"\"\"\n    response = Response(\n        json.dumps(data, ensure_ascii=False),\n        status=status,\n        mimetype=\"application/json\"\n    )\n    for key, value in CORS_HEADERS.items():\n        response.headers[key] = value\n    return response\n\n\n@functions_framework.http\ndef get_words(request: Request) -\u003e Response:\n    \"\"\"HTTP Cloud Function to get vocabulary words.\n    \n    Retrieves up to 30 days of words starting from today.\n    Returns available words even if some dates are missing.\n    \n    Args:\n        request: Flask request object.\n        \n    Returns:\n        JSON response with words list.\n    \"\"\"\n    # Handle CORS preflight request\n    if request.method == \"OPTIONS\":\n        return create_response({}, HTTPStatus.NO_CONTENT)\n\n    if request.method != \"GET\":\n        return create_response(\n            {\"error\": \"Method not allowed\"},\n            HTTPStatus.METHOD_NOT_ALLOWED\n        )\n\n    try:\n        # Get optional query parameters\n        days = request.args.get(\"days\", default=30, type=int)\n        days = min(max(days, 1), 30)  # Clamp between 1 and 30\n        \n        # Calculate date range\n        today = date.today()\n        end_date = today + timedelta(days=days - 1)\n        \n        # Fetch words from Firestore\n        client = FirestoreClient()\n        words = client.get_words_by_date_range(today, end_date)\n        \n        # Return available words (no error even if some dates are missing)\n        return create_response({\n            \"success\": True,\n            \"count\": len(words),\n            \"words\": words,\n            \"date_range\": {\n                \"start\": today.isoformat(),\n                \"end\": end_date.isoformat()\n            }\n        })\n        \n    except Exception as e:\n        logger.error(f\"Error fetching words: {e}\")\n        return create_response(\n            {\n                \"success\": False,\n                \"error\": \"Internal server error\",\n                \"words\": []\n            },\n            HTTPStatus.INTERNAL_SERVER_ERROR\n        )\n",
                "filename": "main.py"
              },
              {
                "content": "functions-framework==3.*\ngoogle-cloud-firestore\u003e=2.14.0\nflask\u003e=2.0.0\n",
                "filename": "requirements.txt"
              }
            ],
            "source_content": null,
            "source_content_filename": null,
            "source_dir": null,
            "source_file": null,
            "type": "zip"
          },
          "sensitive_attributes": [],
          "identity_schema_version": 0
        }
      ]
    }
  ],
  "check_results": null
}
